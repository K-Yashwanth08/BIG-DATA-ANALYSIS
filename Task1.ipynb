{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E2dWpZlWnZk",
        "outputId": "b8c5c19b-1c9c-4712-fe71-025af307176c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CODTECH_BIG_DATA_TASK\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"/content/yellow_tripdata_2015-01.csv\", header=True, inferSchema=True)\n",
        "print(\"Data Loaded Successfully\")\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "id": "BZ8Hx1aXXADP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43ecd42-e9da-4be0-be30-b02a9cc18aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded Successfully\n",
            "+--------+--------------------+---------------------+---------------+-------------+-------------------+------------------+----------+------------------+-------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
            "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|   pickup_longitude|   pickup_latitude|RateCodeID|store_and_fwd_flag|  dropoff_longitude|  dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
            "+--------+--------------------+---------------------+---------------+-------------+-------------------+------------------+----------+------------------+-------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
            "|       2| 2015-01-15 19:05:39|  2015-01-15 19:23:42|              1|         1.59|   -73.993896484375|40.750110626220703|         1|                 N|-73.974784851074219|40.750617980957031|           1|         12|    1|    0.5|      3.25|           0|                  0.3|       17.05|\n",
            "|       1| 2015-01-10 20:33:38|  2015-01-10 20:53:28|              1|         3.30| -74.00164794921875|  40.7242431640625|         1|                 N|-73.994415283203125|40.759109497070313|           1|       14.5|  0.5|    0.5|         2|           0|                  0.3|        17.8|\n",
            "|       1| 2015-01-10 20:33:38|  2015-01-10 20:43:41|              1|         1.80|-73.963340759277344|40.802787780761719|         1|                 N|-73.951820373535156|40.824413299560547|           2|        9.5|  0.5|    0.5|         0|           0|                  0.3|        10.8|\n",
            "|       1| 2015-01-10 20:33:39|  2015-01-10 20:35:31|              1|          .50|-74.009086608886719|40.713817596435547|         1|                 N|-74.004325866699219|40.719985961914063|           2|        3.5|  0.5|    0.5|         0|           0|                  0.3|         4.8|\n",
            "|       1| 2015-01-10 20:33:39|  2015-01-10 20:52:58|              1|         3.00|-73.971176147460938|40.762428283691406|         1|                 N|-74.004180908203125|40.742652893066406|           2|         15|  0.5|    0.5|         0|           0|                  0.3|        16.3|\n",
            "+--------+--------------------+---------------------+---------------+-------------+-------------------+------------------+----------+------------------+-------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.dropna()\n",
        "print(\"Rows after cleaning:\", df_clean.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKQ_-rpxbkwg",
        "outputId": "c1dd9b8b-6af2-415a-9ecd-4428d6c8190c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows after cleaning: 14033457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Rows:\", df_clean.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9edYJ6qLcAxS",
        "outputId": "c80d26df-2293-483b-8ad2-1115164dbefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Rows: 14033457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, col, when\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df_clean2 = df_clean.withColumn(\n",
        "    \"fare_amount_clean\",\n",
        "    when(col(\"fare_amount\").rlike(r\"^-?\\d+(\\.\\d+)?$\"), col(\"fare_amount\").cast(DoubleType()))\n",
        "    .otherwise(None)\n",
        ")\n",
        "\n",
        "df_clean2.select(avg(\"fare_amount_clean\").alias(\"Average Fare\")).show()\n",
        "\n",
        "\n",
        "df_clean.select(avg(when(col(\"fare_amount\").rlike(r\"^-?\\d*\\.?\\d+$\"), col(\"fare_amount\").cast(DoubleType())).otherwise(None))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orH-SgxucaE3",
        "outputId": "db1704a5-7d7c-4d59-f104-0f6823dff4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|       Average Fare|\n",
            "+-------------------+\n",
            "|6.951980371939585E7|\n",
            "+-------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------------+\n",
            "|avg(CASE WHEN RLIKE(fare_amount, ^-?\\d*\\.?\\d+$) THEN CAST(fare_amount AS DOUBLE) ELSE NULL END)|\n",
            "+-----------------------------------------------------------------------------------------------+\n",
            "|                                                                            6.951974427240919E7|\n",
            "+-----------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_clean2.dropna(subset=[\"fare_amount_clean\"])\n"
      ],
      "metadata": {
        "id": "Cv0wCOA2ejHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_final = df_final.withColumn(\n",
        "    \"total_amount_clean\",\n",
        "    col(\"total_amount\").cast(DoubleType())\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "CoKf3G3Ufn8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when, regexp_replace\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "df_final = df_final.withColumn(\n",
        "    \"total_amount_clean\",\n",
        "    when(col(\"total_amount\").rlike(r\"^-?\\d+(\\.\\d+)?$\"), col(\"total_amount\").cast(DoubleType()))\n",
        "    .otherwise(None)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "u-EGR5ALf9SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.groupBy(\"payment_type\") \\\n",
        "    .sum(\"total_amount_clean\") \\\n",
        "    .orderBy(\"sum(total_amount_clean)\", ascending=False) \\\n",
        "    .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5YxXypsgY4F",
        "outputId": "081e326b-f017-4406-d230-d0e056b2ff7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------------------+\n",
            "|       payment_type|sum(total_amount_clean)|\n",
            "+-------------------+-----------------------+\n",
            "|                  1|   7.001692323764845E15|\n",
            "|                  2|   4.985202414510723E13|\n",
            "|                  3|     501605.69696577213|\n",
            "|                  4|     137494.37381088323|\n",
            "|                  N|                 139.32|\n",
            "|                  5|      54.34564743041992|\n",
            "|-73.782073974609375|                   52.0|\n",
            "|                  6|        40.808837890625|\n",
            "|-73.941566467285156|                   30.0|\n",
            "|              14375|                   21.0|\n",
            "|-73.958961486816406|                   18.0|\n",
            "|-74.007865905761719|                   16.5|\n",
            "|-73.982139587402344|                   15.0|\n",
            "|  1.986671447753906|                   12.5|\n",
            "|-73.971481323242187|                   10.0|\n",
            "|-73.962623596191406|                    9.5|\n",
            "|     18685607910156|                    9.5|\n",
            "|-73.954498291015625|                    9.0|\n",
            "|              46875|                    7.5|\n",
            "|-73.997795104980469|                    7.0|\n",
            "+-------------------+-----------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    }
  ]
}